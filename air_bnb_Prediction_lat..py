# -*- coding: utf-8 -*-
"""airbnb_prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/igupta967937/Machine_Learning_Air_Bnb./blob/main/airbnb_prediction_new1.ipynb
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

def p2f(x):
    return float(x.strip('%'))/100

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import statsmodels.api as sm
import gzip
import shutil
import matplotlib.font_manager as font_manager

"""Unzip the gz file"""

with gzip.open('listings.csv.gz', 'rb') as f_in:
    with open('listings.csv', 'wb') as f_out:
        shutil.copyfileobj(f_in, f_out)

"""Reading CSV file. Th etotal number of rows in listing is 44666"""

pd.set_option('precision', 4)
df_listing = pd.read_csv('listings.csv')

df_listing.shape

import itertools
import scipy as sp
import pymc3 as pm3
from scipy import stats
from IPython.core.pylabtools import figsize
import os
figsize(12, 12)
sns.set_style('darkgrid')

"""Remove unwanted chracters from price. Convert price to float. Select properties with price more than 0"""

df_listing['price'] = df_listing['price'].str.replace('$', '')
df_listing['price'] = df_listing['price'].str.replace(',', '')
df_listing["price"] = pd.to_numeric(df_listing["price"], downcast="float")
df_listing = df_listing[df_listing.price > 0]

df_listing.isnull().sum().sort_values(ascending=False)

df_listing.columns

df_to = df_listing[['reviews_per_month', 'number_of_reviews', 'host_response_rate', 'instant_bookable', 'review_scores_communication', 'price']]

df_to

df_to['reviews_per_month'] = df_to['reviews_per_month'].fillna(0)
df_to['host_response_rate'] = df_to['host_response_rate'].fillna(0)
df_to['review_scores_communication'] = df_to['review_scores_communication'].fillna(0)
df_to['instant_bookable'] = df_to['instant_bookable'].astype('category')
df_to['reviews_per_month'] = df_to['reviews_per_month'].astype('int32')

df_to['host_response_rate'] = df_to['host_response_rate'].astype('str')
df_to['host_response_rate'] = df_to['host_response_rate'].apply(p2f)

df_to

y = df_listing['price'].values
df_to

df_to = pd.get_dummies(df_to)

X = df_to.values

"""* Let us look at one of the columns. 
* We see below that we have a very large variety of numbers, let us apply next a preprocessing step. 
"""

X[:,1]

from sklearn import preprocessing
X[:,1] = preprocessing.scale(X[:,1])

X

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

names = df_to.columns.tolist()

X_train

variables = df_to.columns

variables  = np.asarray(variables)

import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import Lasso as ls
from sklearn.metrics import r2_score as r2
figsize(6,6)


a = 0.1
ls = ls(alpha=a)

y_pred_lasso = ls.fit(X_train, y_train).predict(X_test)
r2_score_lasso = r2(y_test, y_pred_lasso)
print(ls)
print("r^2 on test data : %f" % r2_score_lasso)

#######

###############################################################################

from sklearn import ensemble as ens
###############################################################################
# Fit regression model
parameters_for_variables = {'n_estimators': 1000, 'max_depth': 20, 'min_samples_split': 17, 'max_features': 1.0,
          'learning_rate': 0.01, 'loss': 'huber'}
cld = ens.GradientBoostingRegressor(**parameters_for_variables)

cld.fit(X_train, y_train)
mse = mean_squared_error(y_test, cld.predict(X_test))
print("MSE: %.4f" % mse)

###############################################################################
# Plot training deviance

# compute test set deviance
test_score = np.zeros((parameters_for_variables['n_estimators'],), dtype=np.float64)

for i, y_pred in enumerate(cld.staged_predict(X_test)):
    test_score[i] = cld.loss_(y_test, y_pred)

plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.title('Deviance')
plt.plot(np.arange(parameters_for_variables['n_estimators']) + 1, cld.train_score_, 'b-',
         label='Training Set Deviance')
plt.plot(np.arange(parameters_for_variables['n_estimators']) + 1, test_score, 'r-',
         label='Test Set Deviance')
plt.legend(loc='upper right')
plt.xlabel('Boosting Iterations')
plt.ylabel('Deviance')